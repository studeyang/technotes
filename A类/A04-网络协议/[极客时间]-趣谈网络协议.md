# 02 | 网络分层的真实含义是什么？

**这四个问题你真的懂了吗？**

- TCP 在进行三次握手的时候，IP 层和 MAC 层对应都有什么操作呢？
- A 知道自己的下一个中转站是 B，那从 A 发出来的包，应该把 B 的IP地址放在哪里呢？B 知道自己的下一个中转站是 C，从 B 发出来的包，应该把 C 的IP地址放在哪里呢？如果放在 IP 协议中的目标地址，那包到了中转站，怎么知道最终的目的地址是 D 呢？
- 二层设备处理的通常是 MAC 层的东西，二层设备处理的包里，有没有 HTTP 层的内容呢？
- 你打开一个电商网站，都需要经历哪些过程？

**网络为什么要分层？**

复杂的程序都要分层，这是程序设计的要求。比如，复杂的电商还会分数据库层、缓存层、Compose 层、Controller 层和接入层，每一层专注做本层的事情。

**程序是如何工作的？**

<img src="https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119091848.jpg" style="zoom: 80%;" />

**揭秘层与层之间的关系**

只要是在网络上跑的包，都是完整的。可以有下层没上层，绝对不可能有上层没下层。所以，对 TCP 协议来说，三次握手也好，重试也好，只要想发出去包，就要有 IP 层和 MAC 层，不然是发不出去的。

# 03 | ifconfig：最熟悉又陌生的命令行

除了`ifconfig`命令外，可以通过`ip addr`查看本机`ip`地址。

```shell
root@test:~# ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff
    inet 10.100.122.2/24 brd 10.100.122.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::f816:3eff:fec7:7975/64 scope link 
       valid_lft forever preferred_lft forever
```

本来 32 位的 IP 地址就不够，还被分成了 5 类。现在想想，当时分配地址的时候，真是太奢侈了。

<img src="https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119091903.jpg" style="zoom: 80%;" />

在网络地址中，至少在当时设计的时候，对于 A、B、 C 类主要分两部分，前面一部分是网络号，后面一部分是主机号。

<img src="https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119091915.jpg" style="zoom:80%;" />

# 10 | UDP 协议：因性善而简单，难免碰到“城会玩”

**TCP 和 UDP 有哪些区别？**

TCP 是面向连接的，UDP 是面向无连接的。所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。

TCP 提供可靠交付。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。而 UDP 继承了 IP 包的特性，不保证不丢失，不保证按顺序到达。

TCP 是面向字节流的。发送的时候发的是一个流，没头没尾。IP 包可不是一个流，而是一个个的 IP 包。之所以变成了流，这也是 TCP 自己的状态维护做的事情。而 UDP 继承了 IP 的特性，基于数据报的，一个一个地发，一个一个地收。

TCP 是可以有拥塞控制的。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。UDP 就不会，应用让我发，我就发，管它洪水滔天。

**UDP 包头是什么样的？**

无论应用程序是使用 TCP 传数据，还是 UDP 传数据，都要监听一个端口。

<img src="https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119091930.jpg"  />

# 11 | TCP 协议（上）：因性恶而复杂，先恶后善反轻松

**TCP 包头格式**

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119091936.jpg)

- 源端口号和目标端口号：保证数据流发给哪个应用。
- 包的序号：编好号确认哪个先来，哪个后到，是为了解决乱序的问题。
- 确认序号：发出去的包应该有确认，如果没有收到就应该重新发送，直到送达。
- 状态位：SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接，PSH 是数据推送。
- 窗口大小：TCP 要做流量控制，通信双方各声明一个窗口，标识自己当前能够的处理能力。

除了做流量控制以外，TCP 还会做拥塞控制。

**TCP 三次握手**

TCP 的连接建立，需要经历“请求->应答->应答之应答”的三个回合，称为三次握手。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119091944.jpg)

为什么两次握手不行？

A 建立连接的时候，请求包重复发了几次，有的请求包绕了一大圈又回来了，B 会认为这也是一个正常的的请求的话，因此建立了连接。有问题。

三次握手除了双方建立连接外，主要还是为了沟通一件事情，就是 TCP 包的序号的问题。

每个连接都要有不同的序号。这个序号的起始序号是随着时间变化的，可以看成一个 32 位的计数器，每 4ms 加一。为什么序号不能都从 1 开始呢？因为这样往往会出现冲突。

**TCP 四次挥手**

好了，说完了连接，接下来说一说“拜拜”，好说好散。这常被称为四次挥手。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119091956.jpg)

断开的时候，我们可以看到，当 A 说“不玩了”，就进入 FIN_WAIT_1 的状态，B 收到“A 不玩”的消息后，发送知道了，就进入 CLOSE_WAIT 的状态。

A 收到“B 说知道了”，就进入 FIN_WAIT_2 的状态，如果这个时候 B 直接跑路，则 A 将永远在这个状态。TCP 协议里面并没有对这个状态的处理，但是 Linux 有，可以调整`tcp_fin_timeout`这个参数，设置一个超时时间。

如果 B 没有跑路，发送了“B 也不玩了”的请求到达 A 时，A 发送“知道 B 也不玩了”的 ACK 后，从 FIN_WAIT_2 状态结束，按说 A 可以跑路了，但是最后的这个 ACK 万一 B 收不到呢？则 B 会重新发一个“B 不玩了”，这个时候 A 已经跑路了的话，B 就再也收不到 ACK 了，因而 TCP 协议要求 A 最后等待一段时间 TIME_WAIT，这个时间要足够长，长到如果 B没收到 ACK 的话，“B 说不玩了”会重发的，A 会重新发一个 ACK 并且足够时间到达 B。

A 直接跑路还有一个问题是，A 的端口就直接空出来了，但是 B 不知道，B 原来发过的很多包很可能还在路上，如果 A 的端口被一个新的应用占用了，这个新的应用会收到上个连接中 B 发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来 B 发送的所有的包都死翘翘，再空出端口来。

等待的时间设为 2MSL，**MSL** 是 **Maximum Segment Lifetime**，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文是基于 IP 协议的，而 IP 头中有一个 TTL 域，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。协议规定 MSL 为 2 分钟，实际应用中常用的是 30 秒，1 分钟和 2 分钟等。

还有一个异常情况就是，B 超过了 2MSL 的时间，依然没有收到它发的 FIN 的 ACK，怎么办呢？按照 TCP 的原理，B 当然还会重发 FIN，这个时候 A 再收到这个包之后，A 就表示，我已经在这里等了这么长时间了，已经仁至义尽了，之后的我就都不认了，于是就直接发送 RST，B 就知道 A 早就跑了。

下面是一道情景面试：

<img src="https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092004.jpg" style="zoom: 67%;" />

**TCP 状态机**

将连接建立和连接断开的两个时序状态图综合起来，就是这个著名的 TCP 的状态机。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092028.jpg)

在这个图中，加黑加粗的部分，是上面说到的主要流程，其中阿拉伯数字的序号，是连接过程中的顺序，而大写中文数字的序号，是连接断开过程中的顺序。加粗的实线是客户端A的状态变迁，加粗的虚线是服务端B的状态变迁。

# （补充）TIME_WAIT：隐藏在细节下的魔鬼

> 来源于盛延敏极客专栏《网络编程实战》第10讲

**TIME_WAIT 的作用**

首先，这样做是为了确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。

第二，为了让旧连接的重复分节在网络中自然消失。

**TIME_WAIT 的危害**

第一是内存资源占用，这个目前看来不是太严重，基本可以忽略。

第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口。要知道，端口资源也是有限的，一般可以开启的端口为 32768～61000。

**如何优化 TIME_WAIT？**

- net.ipv4.tcp_max_tw_buckets

  这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将所有的 TIME_WAIT 连接状态重置，并且只打印出警告信息。这个方法过于暴力，而且治标不治本，带来的问题远比解决的问题多，不推荐使用。

- 调低 TCP_TIMEWAIT_LEN，重新编译系统

  这个方法是一个不错的方法，缺点是需要“一点”内核方面的知识，能够重新编译内核。我想这个不是大多数人能接受的方式。

- SO_LINGER 的设置

  英文单词“linger”的意思为停留，我们可以通过设置套接字选项，来设置调用 close 或者 shutdown 关闭连接时的行为。

- net.ipv4.tcp_tw_reuse：更安全的设置

  从协议角度理解如果是安全可控的，可以复用处于 TIME_WAIT 的套接字为新的连接所用。

# 12 | TCP协议（下）：西行必定多妖孽，恒心智慧消磨难

**如何做个靠谱的人？**

需要很多的机制去保证传输的可靠性，这里面需要恒心，也即各种重传的策略，还需要有智慧，也就是说，这里面包含着大量的算法。

**如何实现一个靠谱的协议？**

- 累计确认或者累计应答（cumulative acknowledgment）：为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是会应答某个之前的 ID，表示都收到了。


为了记录所有发送的包和接收的包，TCP 也需要发送端和接收端分别都有缓存来保存这些记录。发送端的缓存里是按照包的 ID 一个个排列，根据处理的情况分成四个部分。

第一部分：发送了并且已经确认的。这部分就是你交代下属的，并且也做完了的，应该划掉的。

第二部分：发送了并且尚未确认的。这部分是你交代下属的，但是还没做完的，需要等待做完的回复之后，才能划掉。

第三部分：没有发送，但是已经等待发送的。这部分是你还没有交代给下属，但是马上就要交代的。

第四部分：没有发送，并且暂时还不会发送的。这部分是你还没有交代给下属，而且暂时还不会交代给下属的。

- 窗口控制：在 TCP 里，接收端会给发送端报一个窗口的大小，叫 **Advertised window**。这个窗口的大小应该等于上面的第二部分加上第三部分，就是已经交代了没做完的加上马上要交代的。超过这个窗口的，接收端做不过来，就不能发送了。


于是，发送端需要保持下面的数据结构。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092038.jpg)

LastByteAcked：第一部分和第二部分的分界线；<br>LastByteSent：第二部分和第三部分的分界线；<br>LastByteAcked + AdvertisedWindow：第三部分和第四部分的分界线。

对于接收端来讲，它的缓存里记录的内容要简单一些。

第一部分：接受并且确认过的。也就是我领导交代给我，并且我做完的。<br>第二部分：还没接收，但是马上就能接收的。也即是我自己的能够接受的最大工作量。<br>第三部分：还没接收，也没法接收的。也即超过工作量的部分，实在做不完。

对应的数据结构就像这样。 ﻿﻿

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092045.jpg)

MaxRcvBuffer：最大缓存的量；<br>LastByteRead 之后是已经接收了，但是还没被应用层读取的；<br>NextByteExpected 是第一部分和第二部分的分界线。

第二部分的窗口有多大呢？

NextByteExpected 和 LastByteRead 的差其实是还没被应用层读取的部分占用掉的 MaxRcvBuffer 的量，我们定义为 A。AdvertisedWindow 其实是 MaxRcvBuffer 减去 A。也就是：

AdvertisedWindow = MaxRcvBuffer - ((NextByteExpected - 1) - LastByteRead)。

那第二部分和第三部分的分界线在哪里呢？NextByteExpected 加 AdvertisedWindow 就是第二部分和第三部分的分界线，其实也就是 LastByteRead加上MaxRcvBuffer。

**顺序问题与丢包问题**

我们结合一个例子来看。还是刚才的图，在发送端来看，1、2、3 已经发送并确认；4、5、6、7、8、9 都是发送了还没确认；10、11、12 是还没发出的；13、14、15 是接收方没有空间，不准备发的。

在接收端来看，1、2、3、4、5 是已经完成 ACK，但是没读取的；6、7 是等待接收的；8、9 是已经接收，但是没有 ACK 的。

发送端和接收端当前的状态如下：

1、2、3 没有问题，双方达成了一致。<br>4、5 接收方说 ACK 了，但是发送方还没收到，有可能丢了，有可能在路上。<br>6、7、8、9 肯定都发了，但是 8、9 已经到了，但是 6、7 没到。

出现了乱序，缓存着但是没办法 ACK。

根据这个例子，我们可以知道，顺序问题和丢包问题都有可能发生。

- 确认与重发机制

假设 4 的确认到了，不幸的是，5 的 ACK 丢了，6、7 的数据包丢了，这该怎么办呢？

一种方法就是**超时重试**，也即对每一个发送了，但是没有 ACK 的包，都有设一个定时器，超过了一定的时间，就重新尝试。但是这个超时的时间如何评估呢？这个时间不宜过短，时间必须大于往返时间 RTT，否则会引起不必要的重传。也不宜过长，这样超时时间变长，访问就变慢了。

估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为**自适应重传算法**（**Adaptive Retransmission Algorithm**）。

如果过一段时间，5、6、7 都超时了，就会重新发送。接收方发现 5 原来接收过，于是丢弃 5；6 收到了，发送 ACK，要求下一个是 7，7 不幸又丢了。当 7 再次超时的时候，有需要重传的时候，TCP 的策略是**超时间隔加倍**。**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍**。**两次超时，就说明网络环境差，不宜频繁反复发送。**

超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？

有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。

例如，接收方发现 6、8、9 都已经接收了，就是7没来，那肯定是丢了，于是发送三个 6 的 ACK，要求下一个是 7。客户端收到 3 个，就会发现 7 的确又丢了，不等超时，马上重发。

还有一种方式称为 **Selective Acknowledgment** （**SACK**）。这种方式需要在 TCP 头里加一个 SACK 的东西，可以将缓存的地图发送给发送方。例如可以发送 ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是 7 丢了。

**流量控制问题**

我们再来看流量控制机制，在对于包的确认中，同时会携带一个窗口的大小。我们先假设窗口不变的情况，窗口始终为 9。4 的确认来的时候，会右移一个，这个时候第 13 个包也可以发送了。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092054.jpg)

这个时候，假设发送端发送过猛，会将第三部分的 10、11、12、13 全部发送完毕，之后就停止发送了，未发送可发送部分为 0。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092100.jpg)

当对于包 5 的确认到达的时候，在客户端相当于窗口再滑动了一格，这个时候，才可以有更多的包可以发送了，例如第 14 个包才可以发送。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092107.jpg)

如果接收方实在处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为 0，则发送方将暂时停止发送。

我们假设一个极端情况，接收端的应用一直不读取缓存中的数据，当数据包 6 确认后，窗口大小就不能再是 9 了，就要缩小一个变为 8。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092112.jpg)

这个新的窗口 8 通过 6 的确认消息到达发送端的时候，你会发现窗口没有平行右移，而是仅仅左面的边右移了，窗口的大小从 9 改成了 8。

<!-- 接收方发送6的ACK，同时也应该发送接收方的缓存信息吧？不然发送方怎么知道接收方的缓存满了？ -->

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092119.jpg)

如果接收端还是一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为 0。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092125.jpg)

当这个窗口通过包 14 的确认到达发送端的时候，发送端的窗口也调整为 0，停止发送。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092131.jpg)

如果这样的话，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。

这就是我们常说的流量控制。

**拥塞控制问题**

最后，我们看一下拥塞控制的问题，也是通过窗口的大小来控制的，前面的滑动窗口`rwnd`是怕发送方把接收方缓存塞满，而拥塞窗口`cwnd`，是怕把网络塞满。

如果我们设置发送窗口，使得发送但未确认的包为通道的容量，就能够撑满整个管道。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092137.jpg)

如图所示，已经造成了网络拥塞。

假设往返时间为 8s，去 4s，回 4s，每秒发送一个包，每个包 1024byte。已经过去了 8s，则 8 个包都发出去了，其中前 4 个包已经到达接收端，但是 ACK 还没有返回，不能算发送成功。5 - 8 后四个包还在路上，还没被接收。这个时候，整个管道正好撑满，在发送端，已发送未确认的为 8 个包，正好等于带宽，也即每秒发送 1 个包，乘以来回时间 8s。

如果我们在这个基础上再调大窗口，使得单位时间内更多的包可以发送，会出现什么现象呢？

我们来想，原来发送一个包，从一端到达另一端，假设一共经过四个设备，每个设备处理一个包时间耗费 1s，所以到达另一端需要耗费 4s，如果发送的更加快速，则单位时间内，会有更多的包到达这些中间设备，这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这是我们不想看到的。

这个时候，我们可以想其他的办法，例如这个四个设备本来每秒处理一个包，但是我们在这些设备上加缓存，处理不过来的在队列里面排着，这样包就不会丢失，但是缺点是会增加时延，这个缓存的包，4s 肯定到达不了接收端了，如果时延达到一定程度，就会超时重传，也是我们不想看到的。

于是 TCP 的拥塞控制主要来避免两种现象，**包丢失**和**超时重传**。一旦出现了这些现象就说明，发送速度太快了，要慢一点。但是一开始我怎么知道速度多快呢，我怎么知道应该把窗口调整到多大呢？

一条 TCP 连接开始，cwnd 设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd 加一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认 cwnd 加一，两个确认 cwnd 加二，于是一次能够发送四个；当这四个的确认到来的时候，每个确认 cwnd 加一，四个确认 cwnd 加四，于是一次能够发送八个。可以看出这是**指数性的增长**。

涨到什么时候是个头呢？有一个值 ssthresh 为 65535 个字节，当超过这个值的时候，就要小心一点了，不能倒这么快了，可能快满了，再慢下来。

每收到一个确认后，cwnd 增加 1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加 1/8，八个确认一共 cwnd 增加 1，于是一次能够发送九个，变成了线性增长。

但是线性增长还是增长，还是越来越多，直到有一天，水满则溢，出现了拥塞，这时候一般就会一下子降低倒水的速度，等待溢出的水慢慢渗下去。

拥塞的一种表现形式是丢包，需要超时重传，这个时候，将 sshthresh 设为 cwnd/2，将 cwnd 设为 1，重新开始慢启动。这真是一旦超时重传，马上回到解放前。但是这种方式太激进了，将一个高速的传输速度一下子停了下来，会造成网络卡顿。

前面我们讲过**快速重传算法**。当接收端发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速的重传，不必等待超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，cwnd 减半为 cwnd/2，然后sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092146.jpg)

就像前面说的一样，正是这种知进退，使得时延很重要的情况下，反而降低了速度。但是如果你仔细想一下，TCP的拥塞控制主要来避免的两个现象都是有问题的。

**第一个问题**是丢包并不代表着通道满了，也可能是管子本来就漏水。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。

**第二个问题**是TCP的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实TCP只要填满管道就可以了，不应该接着填，直到连缓存也填满。

为了优化这两个问题，后来有了 **TCP BBR 拥塞算法**。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的达到高带宽和低时延的平衡。

![](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20201119092152.jpg)

