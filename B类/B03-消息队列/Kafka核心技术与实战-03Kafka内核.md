> 来源：极客时间《Kafka核心技术与实战》

# 23 | Kafka副本机制详解

所谓的副本机制（Replication），通常是指分布式系统在多台网络互联的机器上保存有相同的数据拷贝。副本机制有什么好处呢？

- 提供数据冗余：增加系统整体的可用性。
- 提供高伸缩性：能够通过增加机器的方式来提升读性能，进而提高读操作吞吐量。
- 改善数据局部性：允许将数据放入与用户地理位置相近的地方，从而降低系统延时。

然而对于 Apache Kafka 而言，目前只能享受到副本机制带来的第 1 个好处。即便如此，副本机制依然是 Kafka 设计架构的核心所在，它也是 Kafka 确保系统高可用和消息高持久性的重要基石。

**副本定义**

所谓副本（Replica），本质就是一个只能追加写消息的提交日志。同一个分区下的所有副本保存有相同的消息序列，这些副本分散保存在不同的 Broker 上，从而能够对抗部分 Broker 宕机带来的数据不可用。

> 在实际生产环境中，每台 Broker 都可能保存有各个主题下不同分区的不同副本，因此，单个 Broker 上存有成百上千个副本的现象是非常正常的。

接下来我们来看一张图，它展示的是一个有 3 台 Broker 的 Kafka 集群上的副本分布情况。

![image-20210715225817802](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210715225817.png)

从这张图中，我们可以看到，主题 1 分区 0 的 3 个副本分散在 3 台 Broker 上，其他主题分区的副本也都散落在不同的 Broker 上，从而实现数据冗余。

**副本角色**

我们该如何确保副本中所有的数据都是一致的呢？

Apache Kafka 采用了基于领导者（Leader-based）的副本机制，工作原理如下图所示：

![image-20210715230922759](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210715230922.png)

对于上图，有几点信息需要明确：

第一，每个分区在创建时都要选举一个副本作为领导者副本，其余的副本则为追随者副本。

第二，在 Kafka 中，追随者副本是不对外提供服务的，所有的请求都必须由领导者副本来处理。

第三，当领导者副本所在的 Broker 宕机时，会立即开启新一轮的领导者选举。

追随者副本不对外提供，Kafka 为什么要这样设计呢？

第一，方便实现 “Read-your-writes”。当你使用生产者 API 向 Kafka 成功写入消息后，可以马上使用消费者 API 去读取刚才生产的消息。

第二，方便实现单调读（Monotonic Reads）。对于一个消费者用户而言，在多次消费消息时，它不会看到某条消息一会儿存在一会儿不存在。

**In-sync Replicas（ISR）**

怎么度量追随者副本与 Leader 不同步呢？

Kafka 引入了 In-sync Replicas，即 ISR 副本集合。ISR 中的副本都是与 Leader 同步的副本，相反，不在 ISR 中的追随者副本就被认为是与 Leader 不同步的。

> Leader 副本天然就在 ISR 中。也就是说，ISR 不只是追随者副本集合，它必然包括 Leader 副本。甚至在某些情况下，ISR 只有 Leader 这一个副本。

能够进入到 ISR 的追随者副本要满足一定的标准，这个标准就是 Broker 端参数 replica.lag.time.max.ms 参数值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔，当前默认值是 10 秒。

> 只要一个 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 就认为该 Follower 副本与 Leader 是同步的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息。

**Unclean Leader Election**

当出现 ISR 为空，就说明 Leader 副本也“挂掉”了，Kafka 需要从非同步副本中选举一个新的 Leader，选举这种副本的过程称为 Unclean 领导者选举。

通常来说，非同步副本（ISR 集合外的副本）落后 Leader 太多，如果选择这些副本作为新 Leader，就可能出现数据的丢失。Broker 端可通过参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举。

开启 Unclean 领导者选举可能会造成数据丢失，但好处是，它使得分区 Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。

反之，禁止 Unclean 领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。

Kafka 赋予了你选择 C 或 A 的权利。我强烈建议你不要开启它，毕竟我们还可以通过其他的方式来提升高可用性。如果为了这点儿高可用性的改善，牺牲了数据一致性，那就非常不值当了。

# 24 | 请求是怎么被处理的？

今天，我们来详细讨论一下 Kafka Broker 端处理请求的全流程。

**常见处理请求的方式**

关于如何处理请求，我们很容易想到的方案有两个。

- 顺序处理请求

伪代码大概是这个样子：

```java
while (true) {
    Request request = accept(connection);
    handle(request);
}
```

这种方式的吞吐量太差，每个请求都必须等待前一个请求处理完毕才能得到处理。适用于请求发送非常不频繁的系统。

- 异步处理请求

伪代码大概是这个样子：

```java
while (true) {
    Request = request = accept(connection);
    Thread thread = new Thread(() -> handle(request););
    thread.start();
}
```

这个方法的好处是，它是完全异步的，每个请求的处理都不会阻塞下一个请求。

缺陷是开销极大，在某些场景下甚至会压垮整个服务。这个方法也只适用于请求发送频率很低的业务场景。

**Kafka 处理请求的方式**

Kafka 使用的是 Reactor 模式。

简单来说，Reactor 模式是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。Reactor 模式的架构图如下：

![image-20210716233202622](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210716233202.png)

根据上图，Reactor 模式主要特点是分发。

Reactor 有个请求分发线程 Dispatcher，也就是图中的 Acceptor，它会将不同的请求下发到多个工作线程中处理。

> Acceptor 线程只是用于请求分发，不涉及具体的逻辑处理，非常轻量级，因此有很高的吞吐量表现。而这些工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力。

Kafka 的处理请求模型类似：

![image-20210716233715438](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210716233715.png)

SocketServer 组件：它也有对应的 Acceptor 线程和一个网络线程池。

Acceptor 线程：采用轮询的方式将入站请求公平地发到所有网络线程中。

网络线程池：处理 Acceptor 线程分发的工作任务。

Kafka 提供了 Broker 端参数 num.network.threads，用于调整该网络线程池的线程数。其默认值是 3，表示每台 Broker 启动时会创建 3 个网络线程，专门处理客户端发送的请求。

**Kafka 网络线程处理请求的具体过程**

客户端发来的请求会被 Broker 端的 Acceptor 线程分发到任意一个网络线程中，Kafka 在这个环节又做了一层异步线程池的处理，我们一起来看一看下面这张图。

![image-20210716234619473](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210716234619.png)

主要步骤如下：

1. 当网络线程拿到请求后，会将请求放入到一个共享请求队列中。

2. Broker 端有个 IO 线程池，负责从该队列中取出请求，执行真正的处理。

   > Broker 端参数 num.io.threads 控制了这个线程池中的线程数。 目前该参数默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程处理请求。

3. 处理请求。如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息。

4. IO 线程处理完请求后，会将生成的响应发送到网络线程池的响应队列中，然后由对应的网络线程负责将 Response 返还给客户端。

> 为什么网络线程不直接处理？即为什么要有 2、3 步骤？

**请求队列与响应队列的差别**

请求队列是所有网络线程共享的，而响应队列则是每个网络线程专属的。

这么设计的原因就在于，Dispatcher 只是用于请求分发而不负责响应回传，因此只能让每个网络线程自己发送 Response 给客户端，所以这些 Response 也就没必要放在一个公共的地方。

**Purgatory 组件**

图中还有一个叫 Purgatory 的组件，这是 Kafka 中著名的“炼狱”组件。它是用来缓存延时请求（Delayed Request）的。

所谓延时请求，就是那些一时未满足条件不能立刻处理的请求。比如设置了 acks=all 的 PRODUCE 请求，一旦设置了 acks=all，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时处理该请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理时，它就会暂存在 Purgatory 中。稍后一旦满足了完成条件，IO 线程会继续处理该请求，并将 Response 放入对应网络线程的响应队列中。

# 25 | 消费者组重平衡全流程解析

> 本篇是基于 Kafka 2.3 版本讲述。

**重平衡触发与通知**

重平衡的 3 个触发条件：

1. 组成员数量发生变化。
2. 订阅主题数量发生变化。
3. 订阅主题的分区数发生变化。

> 助记：组成员、主题数、主题分区。

重平衡过程是如何通知到其他消费者实例的？

重平衡的通知机制是通过消费者端的心跳线程（Heartbeat Thread）来完成的。当协调者决定开启新一轮重平衡后，它会将“REBALANCE_IN_PROGRESS”封装进心跳请求的响应中，发还给消费者实例。当消费者实例发现心跳响应中包含了“REBALANCE_IN_PROGRESS”，就能立马知道重平衡又开始了，这就是重平衡的通知机制。

> 在 Kafka 0.10.1.0 版本之前，发送心跳请求是在消费者主线程完成的，也就是代码调用 KafkaConsumer.poll 方法的那个线程。
>
> 这样做最大的问题在于，消息处理逻辑也是在这个线程中完成的。一旦消息处理消耗了过长的时间，心跳请求将无法及时发到协调者那里，导致协调者“错误地”认为该消费者已“死”。
>
> 自 0.10.1.0 版本开始，社区引入了一个单独的心跳线程来专门执行心跳请求发送，避免了这个问题。

**消费者组状态机**

重平衡一旦开启，Broker 端的协调者组件就要开始忙了，主要涉及到控制消费者组的状态流转。Kafka 设计了一套消费者组状态机（State Machine），来帮助协调者完成整个重平衡流程。

Kafka 为消费者组定义了 5 种状态，它们分别是：Empty、Dead、PreparingRebalance、CompletingRebalance 和 Stable。

| 状态                | 含义                                                         |
| ------------------- | ------------------------------------------------------------ |
| Empty               | 组内没有任何成员，但消费者组可能存在已提交的位移数据，而且这些位移尚未过期。 |
| Dead                | 组内没有任何成员，但组的元数据信息已经在协调者端被移除。     |
| PreparingRebalance  | 消费者组准备开启重平衡，此时所有成员都要重新请求加入消费者组。 |
| CompletingRebalance | 消费者组下所有成员已经加入，各个成员正在等待分配方案。       |
| Stable              | 消息者组的稳定状态。表明重平衡已经完成，组内各成员能够正常消费数据了。 |

下图展示了状态机的各个状态流转。

![image-20210718233601783](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210718233601.png)

一个消费者组最开始是 Empty 状态，当重平衡过程开启后，它会被置于 PreparingRebalance 状态等待成员加入，之后变更到 CompletingRebalance 状态等待分配方案，最后流转到 Stable 状态完成重平衡。

当有新成员加入或已有成员退出时，消费者组的状态从 Stable 直接跳到 PreparingRebalance 状态，此时，所有现存成员就必须重新申请加入组。

当所有成员都退出组后，消费者组状态变更为 Empty。该状态下，Kafka 会定期自动删除过期位移，因此，如果你的消费者组停掉超过 7 天，那么 Kafka 很可能就把该组的位移数据删除了。

> 删除日志打印如下：
>
> Removed xxx expired offsets in xxx milliseconds.

**消费者端重平衡流程**

重平衡的完整流程需要消费者端和协调者组件共同参与才能完成。我们先从消费者的视角来审视一下重平衡的流程。

第一步，发送 JoinGroup 请求。

JoinGroup 请求的主要作用是将组成员订阅信息发送给领导者消费者。

当组内成员加入组时，它会向协调者发送 JoinGroup 请求。在该请求中，每个成员都要将自己订阅的主题上报，这样协调者就能收集到所有成员的订阅信息。一旦收集了全部成员的 JoinGroup 请求后，协调者会从这些成员中选择一个担任这个消费者组的领导者。

> 通常情况下，第一个发送 JoinGroup 请求的成员自动成为领导者。

> 这里的领导者和领导者副本不是一个概念。
>
> 这里的领导者是具体的消费者实例，它既不是副本，也不是协调者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些信息，制定具体的分区消费分配方案。

![image-20210719223343608](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210719223343.png)

选出领导者之后，协调者会把消费者组订阅信息封装进 JoinGroup 请求的响应体中，然后发给领导者，由领导者统一做出分配方案后，进入到第二步。

第二步，发送 SyncGroup 请求。

领导者向协调者发送 SyncGroup 请求，将刚刚做出的分配方案发给协调者。

> 其他成员也会向协调者发送 SyncGroup 请求，只不过请求体中并没有实际的内容。
>
> 这一步的主要目的是让协调者接收分配方案，然后统一以 SyncGroup 响应的方式分发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了。

![image-20210719224406019](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210719224406.png)

协调者把领导者制定的分配方案下发给各个组内成员，当所有成员都成功接收到分配方案后，消费者组进入到 Stable 状态，即开始正常的消费工作。

**Broker 端重平衡场景剖析**

接下来，我们从协调者端来看一下重平衡是怎么执行的。

- 场景一：新成员入组。

组处于 Stable 状态后，如果有新成员加入。

![image-20210719225521378](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210719225521.png)

这里成员 2 作为新成员入组。

- 场景二：组成员主动离组。

指消费者实例所在线程或进程调用 close() 方法主动通知协调者它要退出。

![image-20210719225741739](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210719225741.png)

- 场景三：组成员崩溃离组。

指消费者实例出现严重故障，突然宕机导致的离组。

这种情况下，协调者通常需要等待一段时间才能感知到，这段时间一般是由消费者端参数 session.timeout.ms 控制的。

![image-20210719225949027](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210719225949.png)

- 场景四：重平衡时协调者对组内成员提交位移的处理。

正常情况下，每个组内成员都会定期汇报位移给协调者。

当重平衡开启时，协调者会给予成员一段缓冲时间，要求每个成员必须在这段时间内快速地上报自己的位移信息，然后再开启正常的 JoinGroup/SyncGroup 请求发送。

![image-20210719230634015](https://technotes.oss-cn-shenzhen.aliyuncs.com/2021/images/20210719230634.png)

# 26 | 你一定不能错过的Kafka控制器







